{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "264e1053",
   "metadata": {},
   "source": [
    "# –†–∞–∑–¥–µ–ª 1 ‚Äî –°–±–æ—Ä —Ç–µ–∫—Å—Ç–æ–≤ (VK / —Å–∞–π—Ç—ã / –Ø–Ω–¥–µ–∫—Å –û—Ç–∑—ã–≤—ã)\n",
    "\n",
    "–í —ç—Ç–æ–º —Ä–∞–∑–¥–µ–ª–µ –º—ã –ø—Ä–∏–≤–æ–¥–∏–º —Ç–µ–∫—Å—Ç—ã –∏–∑ —Ä–∞–∑–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –∫ **–µ–¥–∏–Ω–æ–º—É —Ñ–æ—Ä–º–∞—Ç—É** —Ç–∞–±–ª–∏—Ü—ã `docs`.\n",
    "\n",
    "## –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –∫—É—Ä—Å–∞\n",
    "- –ò—Å–ø–æ–ª—å–∑—É–µ–º **—Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç—ã**.\n",
    "- **LLM –∑–∞–ø—Ä–µ—â–µ–Ω—ã**.\n",
    "- –ù–∏–∫–∞–∫–∏—Ö –≤–Ω–µ—à–Ω–∏—Ö –±–∞–∑, —Ç—Ä–µ–±—É—é—â–∏—Ö –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–π —Ä–∞–∑–º–µ—Ç–∫–∏.\n",
    "- –î–æ–ø—É—Å—Ç–∏–º–æ: –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ + BERT/—ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –∏ –º–µ—Ç–æ–¥—ã –Ω–∞ –∏—Ö –æ—Å–Ω–æ–≤–µ (–≤ —Å–ª–µ–¥—É—é—â–∏—Ö —Ä–∞–∑–¥–µ–ª–∞—Ö).\n",
    "\n",
    "## –ï–¥–∏–Ω–∞—è —Å—Ö–µ–º–∞ –¥–∞–Ω–Ω—ã—Ö `docs`\n",
    "- `doc_id`: —É–Ω–∏–∫–∞–ª—å–Ω—ã–π ID –¥–æ–∫—É–º–µ–Ω—Ç–∞\n",
    "- `source`: `vk | website | yandex_reviews`\n",
    "- `text_raw`: –∏—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç\n",
    "- `text_clean`: –æ—á–∏—â–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç (–≤ —ç—Ç–æ–º —Ä–∞–∑–¥–µ–ª–µ ‚Äî –ø—Ä–æ—Å—Ç–∞—è –±–∞–∑–æ–≤–∞—è –æ—á–∏—Å—Ç–∫–∞)\n",
    "- `date`: –¥–∞—Ç–∞ (–µ—Å–ª–∏ –µ—Å—Ç—å)\n",
    "- `url`: —Å—Å—ã–ª–∫–∞ –Ω–∞ –∏—Å—Ç–æ—á–Ω–∏–∫ (–µ—Å–ª–∏ –µ—Å—Ç—å)\n",
    "- `meta`: —Å–ª–æ–≤–∞—Ä—å —Å –¥–æ–ø. –ø–æ–ª—è–º–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –≥—Ä—É–ø–ø–∞ VK, —Ä–µ–π—Ç–∏–Ω–≥, –∑–∞–≥–æ–ª–æ–≤–æ–∫)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa9d350",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import re\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d641685",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib.util\n",
    "\n",
    "_is_colab = importlib.util.find_spec('google.colab') is not None\n",
    "if _is_colab:\n",
    "    from google.colab import output  # type: ignore\n",
    "    output.enable_custom_widget_manager()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b8a062",
   "metadata": {},
   "source": [
    "## –ü–∞–Ω–µ–ª—å —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è\n",
    "–í—ã–±–µ—Ä–∏—Ç–µ –∏—Å—Ç–æ—á–Ω–∏–∫ –∏ –≤–≤–µ–¥–∏—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã. –î–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ –º–æ–∂–Ω–æ –Ω–∞–∂–∞—Ç—å **¬´–ó–∞–≥—Ä—É–∑–∏—Ç—å DEMO-–∫–æ—Ä–ø—É—Å¬ª**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa6916e",
   "metadata": {
    "cellView": "form",
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "#@title –§–æ—Ä–º–∞ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è { display-mode: \"form\" }\n",
    "source_dd = widgets.Dropdown(\n",
    "    options=[(\"VK (—Å—Ç–µ–Ω—ã –≥—Ä—É–ø–ø)\", \"vk\"), (\"–°–∞–π—Ç—ã\", \"website\"), (\"–Ø–Ω–¥–µ–∫—Å –û—Ç–∑—ã–≤—ã\", \"yandex_reviews\")],\n",
    "    value=\"vk\",\n",
    "    description=\"–ò—Å—Ç–æ—á–Ω–∏–∫:\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    "    layout=widgets.Layout(width=\"420px\"),\n",
    ")\n",
    "\n",
    "input_ta = widgets.Textarea(\n",
    "    value=\"\",\n",
    "    placeholder=\"–î–ª—è VK: ID –≥—Ä—É–ø–ø —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é\\n–î–ª—è —Å–∞–π—Ç–æ–≤: URL-—ã –ø–æ —Å—Ç—Ä–æ–∫–∞–º\\n–î–ª—è –Ø–Ω–¥–µ–∫—Å –û—Ç–∑—ã–≤–æ–≤: URL-—ã –ø–æ —Å—Ç—Ä–æ–∫–∞–º\",\n",
    "    description=\"–í–≤–æ–¥:\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    "    layout=widgets.Layout(width=\"820px\", height=\"140px\"),\n",
    ")\n",
    "\n",
    "since_txt = widgets.Text(\n",
    "    value=\"\",\n",
    "    placeholder=\"YYYY-MM-DD (–Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ)\",\n",
    "    description=\"–ü–µ—Ä–∏–æ–¥ —Å:\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    "    layout=widgets.Layout(width=\"260px\"),\n",
    ")\n",
    "\n",
    "until_txt = widgets.Text(\n",
    "    value=\"\",\n",
    "    placeholder=\"YYYY-MM-DD (–Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ)\",\n",
    "    description=\"–ü–µ—Ä–∏–æ–¥ –ø–æ:\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    "    layout=widgets.Layout(width=\"260px\"),\n",
    ")\n",
    "\n",
    "demo_btn = widgets.Button(description=\"–ó–∞–≥—Ä—É–∑–∏—Ç—å DEMO-–∫–æ—Ä–ø—É—Å\", button_style=\"info\")\n",
    "run_btn = widgets.Button(description=\"–ó–∞–ø—É—Å—Ç–∏—Ç—å —Å–±–æ—Ä (stub)\", button_style=\"primary\")\n",
    "\n",
    "out = widgets.Output()\n",
    "\n",
    "display(widgets.VBox([\n",
    "    source_dd,\n",
    "    input_ta,\n",
    "    widgets.HBox([since_txt, until_txt, demo_btn, run_btn]),\n",
    "    out,\n",
    "]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e23efb",
   "metadata": {},
   "source": [
    "## –ë–∞–∑–æ–≤–∞—è –æ—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞\n",
    "–ü–æ–∫–∞ —á—Ç–æ –¥–µ–ª–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω–æ:\n",
    "- —É–±–∏—Ä–∞–µ–º HTML-—Ç–µ–≥–∏,\n",
    "- –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–æ–±–µ–ª—ã,\n",
    "- —Å—Ö–ª–æ–ø—ã–≤–∞–µ–º –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è –∑–Ω–∞–∫–∏.\n",
    "\n",
    "–ë–æ–ª–µ–µ —Å–µ—Ä—å—ë–∑–Ω–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è (–ª–µ–º–º—ã, –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –∏ —Ç.–¥.) ‚Äî –≤ —Å–ª–µ–¥—É—é—â–µ–º —Ä–∞–∑–¥–µ–ª–µ ¬´–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫–æ—Ä–ø—É—Å–∞¬ª."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b278c18e",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "HTML_TAG_RE = re.compile(r\"<[^>]+>\")\n",
    "SPACE_RE = re.compile(r\"\\s+\")\n",
    "PUNCT_RUN_RE = re.compile(r\"([!?.,])\\1{2,}\")\n",
    "\n",
    "def clean_text_minimal(text: str) -> str:\n",
    "    if text is None:\n",
    "        return \"\"\n",
    "    t = str(text)\n",
    "    t = HTML_TAG_RE.sub(\" \", t)\n",
    "    t = PUNCT_RUN_RE.sub(r\"\\1\\1\", t)\n",
    "    t = SPACE_RE.sub(\" \", t).strip()\n",
    "    return t\n",
    "\n",
    "def parse_date_safe(s: str) -> Optional[pd.Timestamp]:\n",
    "    s = (s or \"\").strip()\n",
    "    if not s:\n",
    "        return None\n",
    "    try:\n",
    "        return pd.to_datetime(s)\n",
    "    except Exception:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fae1eac",
   "metadata": {},
   "source": [
    "## Stub-—Ñ—É–Ω–∫—Ü–∏–∏ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤\n",
    "–ó–¥–µ—Å—å **—Ç–æ—á–∫–∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è** –∫ —Ä–µ–∞–ª—å–Ω—ã–º –ø–∞—Ä—Å–µ—Ä–∞–º.\n",
    "\n",
    "‚úÖ VK ‚Äî —É —Ç–µ–±—è —É–∂–µ –µ—Å—Ç—å (—Å—é–¥–∞ –ø—Ä–æ—Å—Ç–æ –ø–æ–¥–∫–ª—é—á–∏–º —Ñ—É–Ω–∫—Ü–∏—é).  \n",
    "üß© –°–∞–π—Ç—ã –∏ –Ø–Ω–¥–µ–∫—Å –û—Ç–∑—ã–≤—ã ‚Äî –ø–æ–∑–∂–µ –¥–æ–±–∞–≤–∏–º —Ä–µ–∞–ª—å–Ω—ã–µ –ø–∞—Ä—Å–µ—Ä—ã.\n",
    "\n",
    "–°–µ–π—á–∞—Å —ç—Ç–∏ —Ñ—É–Ω–∫—Ü–∏–∏ –≤–æ–∑–≤—Ä–∞—â–∞—é—Ç –º–∞–ª–µ–Ω—å–∫–∏–π —Ç–µ—Å—Ç–æ–≤—ã–π –Ω–∞–±–æ—Ä, —á—Ç–æ–±—ã –æ—Å—Ç–∞–ª—å–Ω–æ–π pipeline —Ä–∞–±–æ—Ç–∞–ª."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfe26b5",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "def collect_vk_stub(group_ids: List[str], since: Optional[pd.Timestamp], until: Optional[pd.Timestamp]) -> pd.DataFrame:\n",
    "    rows = [\n",
    "        {\n",
    "            \"doc_id\": \"vk_1\",\n",
    "            \"source\": \"vk\",\n",
    "            \"text_raw\": \"–õ—é–±–ª—é —ç—Ç–æ—Ç —Ä–∞–π–æ–Ω ‚Äî –∑–¥–µ—Å—å —Ç–∏—Ö–æ –∏ –º–Ω–æ–≥–æ –∑–µ–ª–µ–Ω–∏. –ù–æ –ø–∞—Ä–∫–æ–≤–∫–∏ –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç!!!\",\n",
    "            \"date\": pd.Timestamp(\"2025-09-12\"),\n",
    "            \"url\": None,\n",
    "            \"meta\": {\"group_id\": group_ids[0] if group_ids else None},\n",
    "        },\n",
    "        {\n",
    "            \"doc_id\": \"vk_2\",\n",
    "            \"source\": \"vk\",\n",
    "            \"text_raw\": \"–û–ø—è—Ç—å –ø–µ—Ä–µ–∫–æ–ø–∞–ª–∏ —É–ª–∏—Ü—É —É —Å—Ç–∞–Ω—Ü–∏–∏. –î–æ–π—Ç–∏ –¥–æ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ ‚Äî –∫–≤–µ—Å—Ç.\",\n",
    "            \"date\": pd.Timestamp(\"2025-10-03\"),\n",
    "            \"url\": None,\n",
    "            \"meta\": {\"group_id\": group_ids[0] if group_ids else None},\n",
    "        },\n",
    "    ]\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def collect_websites_stub(urls: List[str]) -> pd.DataFrame:\n",
    "    rows = [\n",
    "        {\n",
    "            \"doc_id\": \"web_1\",\n",
    "            \"source\": \"website\",\n",
    "            \"text_raw\": \"<article>–ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–π –∫–≤–∞—Ä—Ç–∞–ª –º–µ–Ω—è–µ—Ç—Å—è: –ø–æ—è–≤–ª—è—é—Ç—Å—è –Ω–æ–≤—ã–µ –∫–∞—Ñ–µ –∏ –º–∞—Å—Ç–µ—Ä—Å–∫–∏–µ.</article>\",\n",
    "            \"date\": None,\n",
    "            \"url\": urls[0] if urls else None,\n",
    "            \"meta\": {\"title\": \"–ó–∞–≥–ª—É—à–∫–∞ —Å—Ç–∞—Ç—å–∏\"},\n",
    "        }\n",
    "    ]\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def collect_yandex_reviews_stub(urls: List[str]) -> pd.DataFrame:\n",
    "    rows = [\n",
    "        {\n",
    "            \"doc_id\": \"ya_1\",\n",
    "            \"source\": \"yandex_reviews\",\n",
    "            \"text_raw\": \"–£–¥–æ–±–Ω–æ –¥–æ–±–∏—Ä–∞—Ç—å—Å—è, –Ω–æ –≤–Ω—É—Ç—Ä–∏ —Ç–µ—Å–Ω–æ. –ü–µ—Ä—Å–æ–Ω–∞–ª –Ω–æ—Ä–º.\",\n",
    "            \"date\": None,\n",
    "            \"url\": urls[0] if urls else None,\n",
    "            \"meta\": {\"rating\": 3, \"place\": \"–ó–∞–≥–ª—É—à–∫–∞\"},\n",
    "        }\n",
    "    ]\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def standardize_docs(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    required_cols = [\"doc_id\", \"source\", \"text_raw\", \"date\", \"url\", \"meta\"]\n",
    "    for c in required_cols:\n",
    "        if c not in df.columns:\n",
    "            df[c] = None\n",
    "    df = df[required_cols].copy()\n",
    "    df[\"text_clean\"] = df[\"text_raw\"].map(clean_text_minimal)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a0c24f",
   "metadata": {},
   "source": [
    "## –ó–∞–ø—É—Å–∫ (DEMO / stub)\n",
    "–ù–∏–∂–µ ‚Äî –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –∫–Ω–æ–ø–æ–∫. –ù–∞ DEMO –º–æ–∂–Ω–æ –æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å—Å—è –∫–∞–∫ –Ω–∞ –æ–∂–∏–¥–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98329495",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "docs: Optional[pd.DataFrame] = None\n",
    "\n",
    "def get_inputs() -> Dict[str, Any]:\n",
    "    src = source_dd.value\n",
    "    raw = input_ta.value.strip()\n",
    "    since = parse_date_safe(since_txt.value)\n",
    "    until = parse_date_safe(until_txt.value)\n",
    "\n",
    "    if src == \"vk\":\n",
    "        items = [x.strip() for x in re.split(r\"[\\n,;]+\", raw) if x.strip()]\n",
    "    else:\n",
    "        items = [x.strip() for x in raw.splitlines() if x.strip()]\n",
    "\n",
    "    return {\"source\": src, \"items\": items, \"since\": since, \"until\": until}\n",
    "\n",
    "def load_demo(_=None):\n",
    "    global docs\n",
    "    with out:\n",
    "        out.clear_output()\n",
    "        demo = pd.concat([\n",
    "            collect_vk_stub([\"demo_group\"], None, None),\n",
    "            collect_websites_stub([\"https://example.com/article\"]),\n",
    "            collect_yandex_reviews_stub([\"https://example.com/reviews\"]),\n",
    "        ], ignore_index=True)\n",
    "        docs = standardize_docs(demo)\n",
    "        display(Markdown(\"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω DEMO-–∫–æ—Ä–ø—É—Å. –ù–∏–∂–µ ‚Äî –ø–µ—Ä–≤—ã–µ —Å—Ç—Ä–æ–∫–∏ `docs`.\"))\n",
    "        display(docs.head(10))\n",
    "\n",
    "def run_stub(_=None):\n",
    "    global docs\n",
    "    cfg = get_inputs()\n",
    "    with out:\n",
    "        out.clear_output()\n",
    "        display(Markdown(\n",
    "            f\"**–ò—Å—Ç–æ—á–Ω–∏–∫:** `{cfg['source']}`  \\\\n\"\n",
    "            f\"**–≠–ª–µ–º–µ–Ω—Ç—ã –≤–≤–æ–¥–∞:** {len(cfg['items'])}  \\\\n\"\n",
    "            f\"**–ü–µ—Ä–∏–æ–¥:** {cfg['since']} ‚Äî {cfg['until']}\"\n",
    "        ))\n",
    "\n",
    "        if cfg[\"source\"] == \"vk\":\n",
    "            df = collect_vk_stub(cfg[\"items\"], cfg[\"since\"], cfg[\"until\"])\n",
    "        elif cfg[\"source\"] == \"website\":\n",
    "            df = collect_websites_stub(cfg[\"items\"])\n",
    "        else:\n",
    "            df = collect_yandex_reviews_stub(cfg[\"items\"])\n",
    "\n",
    "        docs = standardize_docs(df)\n",
    "        display(Markdown(\"‚úÖ –ü–æ–ª—É—á–µ–Ω–∞ —Ç–∞–±–ª–∏—Ü–∞ `docs` (–≤ —Ñ–æ—Ä–º–∞—Ç–µ –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–∏—Ö —Ä–∞–∑–¥–µ–ª–æ–≤).\"))\n",
    "        display(docs)\n",
    "\n",
    "demo_btn.on_click(load_demo)\n",
    "run_btn.on_click(run_stub)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b840bb",
   "metadata": {},
   "source": [
    "## –ë—ã—Å—Ç—Ä—ã–π –∫–æ–Ω—Ç—Ä–æ–ª—å –∫–∞—á–µ—Å—Ç–≤–∞ –∫–æ—Ä–ø—É—Å–∞ (–º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π)\n",
    "–≠—Ç–æ –Ω–µ ‚Äú–ø–æ–ª–Ω—ã–π –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥‚Äù, –∞ sanity-check:\n",
    "- —Å–∫–æ–ª—å–∫–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤,\n",
    "- —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–ª–∏–Ω—ã,\n",
    "- —Ç–æ–ø-—Å–ª–æ–≤–∞ (–æ—á–µ–Ω—å –≥—Ä—É–±–æ)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7daca2ad",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "def quick_qc(docs: pd.DataFrame) -> None:\n",
    "    if docs is None or docs.empty:\n",
    "        display(Markdown(\"‚ö†Ô∏è `docs` –ø—É—Å—Ç–æ–π. –°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ DEMO –∏–ª–∏ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ —Å–±–æ—Ä.\"))\n",
    "        return\n",
    "\n",
    "    df = docs.copy()\n",
    "    df[\"len_chars\"] = df[\"text_clean\"].map(lambda s: len(s or \"\"))\n",
    "    df[\"len_words\"] = df[\"text_clean\"].map(lambda s: len((s or \"\").split()))\n",
    "\n",
    "    display(Markdown(\"### –°–≤–æ–¥–∫–∞\"))\n",
    "    display(df.groupby(\"source\").agg(\n",
    "        n_docs=(\"doc_id\", \"count\"),\n",
    "        avg_words=(\"len_words\", \"mean\"),\n",
    "        p50_words=(\"len_words\", \"median\"),\n",
    "        avg_chars=(\"len_chars\", \"mean\"),\n",
    "    ))\n",
    "\n",
    "    display(Markdown(\"### –î–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞ (—Å–ª–æ–≤)\"))\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure()\n",
    "    df[\"len_words\"].hist(bins=20)\n",
    "    plt.xlabel(\"words\")\n",
    "    plt.ylabel(\"count\")\n",
    "    plt.show()\n",
    "\n",
    "    display(Markdown(\"### –¢–æ–ø-—Å–ª–æ–≤ (–æ—á–µ–Ω—å –≥—Ä—É–±–æ)\"))\n",
    "    token_re = re.compile(r\"[–∞-—è—ë]+\", re.IGNORECASE)\n",
    "    tokens = []\n",
    "    for t in df[\"text_clean\"].astype(str).tolist():\n",
    "        tokens.extend(token_re.findall(t.lower()))\n",
    "    if not tokens:\n",
    "        display(Markdown(\"(–Ω–µ—Ç —Ç–æ–∫–µ–Ω–æ–≤ –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏)\"))\n",
    "        return\n",
    "    vc = pd.Series(tokens).value_counts().head(25)\n",
    "    display(vc.to_frame(\"count\"))\n",
    "\n",
    "if docs is not None:\n",
    "    quick_qc(docs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce85474",
   "metadata": {},
   "source": [
    "## –ß—Ç–æ –¥–∞–ª—å—à–µ\n",
    "–°–ª–µ–¥—É—é—â–∏–π —Ä–∞–∑–¥–µ–ª –∫–Ω–∏–≥–∏: **¬´–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫–æ—Ä–ø—É—Å–∞¬ª** ‚Äî —Ç–∞–º –±—É–¥–µ—Ç:\n",
    "- –±–æ–ª–µ–µ —Å—Ç—Ä–æ–≥–∞—è –æ—á–∏—Å—Ç–∫–∞,\n",
    "- –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è,\n",
    "- –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º –∏ —Ç–µ–º–∞—Ç–∏–∑–∞—Ü–∏–∏."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
